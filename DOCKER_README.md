# Step-Audio-R1.1 Docker éƒ¨ç½²

## ğŸš€ å¿«é€Ÿå¼€å§‹

### å‰ç½®è¦æ±‚
- 4 å¼  NVIDIA GPUï¼ˆæ¯å¼ è‡³å°‘ 35GB æ˜¾å­˜ï¼‰
- Docker + nvidia-docker
- çº¦ 70GB ç£ç›˜ç©ºé—´ï¼ˆæ¨¡å‹ï¼‰

### ä¸€é”®å¯åŠ¨
```bash
./start.sh
```

### åˆ†æ­¥å¯åŠ¨ï¼ˆæ¨èï¼‰

1. **å¯åŠ¨ Web UI**ï¼ˆä¸éœ€è¦ GPUï¼‰
```bash
docker compose -f docker-compose.web.yml up -d
```
è®¿é—®: http://localhost:9100

2. **å¯åŠ¨ vLLM åç«¯**ï¼ˆéœ€è¦ 4 å¼  GPUï¼‰
```bash
./start-vllm.sh
```

## ğŸ“ æ–‡ä»¶è¯´æ˜

| æ–‡ä»¶ | è¯´æ˜ |
|------|------|
| `start.sh` | ä¸€é”®å¯åŠ¨è„šæœ¬ï¼ˆWeb + vLLMï¼‰ |
| `start-vllm.sh` | å•ç‹¬å¯åŠ¨ vLLM åç«¯ |
| `docker-compose.yml` | å®Œæ•´æœåŠ¡é…ç½® |
| `docker-compose.web.yml` | ä»… Web UI é…ç½® |
| `app.py` | Flask Web æœåŠ¡ |
| `mcp_server.py` | MCP æœåŠ¡å™¨ |
| `MCP_GUIDE.md` | MCP ä½¿ç”¨æŒ‡å— |

## ğŸŒ è®¿é—®æ–¹å¼

### Web UI
- åœ°å€: http://0.0.0.0:9100
- åŠŸèƒ½: ä¸Šä¼ éŸ³é¢‘ã€é€‰æ‹©æ¨¡å¼ã€æŸ¥çœ‹ç»“æœ

### REST API
- æ–‡æ¡£: http://0.0.0.0:9100/docs
- å¥åº·æ£€æŸ¥: `GET /health`
- å¤„ç†éŸ³é¢‘: `POST /api/process`
- å¼‚æ­¥ä»»åŠ¡: `POST /api/task`

### MCP
å‚è§ [MCP_GUIDE.md](MCP_GUIDE.md)

## âš™ï¸ é…ç½®

### ç¯å¢ƒå˜é‡
```bash
WEB_PORT=9100          # Web UI ç«¯å£
VLLM_PORT=9999         # vLLM API ç«¯å£
MODEL_PATH=./Step-Audio-R1.1  # æ¨¡å‹è·¯å¾„
```

### GPU é€‰æ‹©
è„šæœ¬ä¼šè‡ªåŠ¨é€‰æ‹©æ˜¾å­˜æœ€å¤šçš„ 4 å¼  GPUã€‚å¦‚éœ€æ‰‹åŠ¨æŒ‡å®šï¼š
```bash
export NVIDIA_VISIBLE_DEVICES=0,1,2,3
```

## ğŸ”§ æ•…éšœæ’é™¤

### GPU æ˜¾å­˜ä¸è¶³
```
ValueError: Free memory on device (X.XX/44.64 GiB) on startup is less than desired GPU memory utilization
```
è§£å†³æ–¹æ¡ˆï¼š
1. åœæ­¢å ç”¨ GPU çš„å…¶ä»–è¿›ç¨‹
2. é™ä½ `--gpu-memory-utilization` å‚æ•°
3. å‡å° `--max-model-len` å‚æ•°

### æŸ¥çœ‹æ—¥å¿—
```bash
docker logs -f step-audio-r1-vllm  # vLLM æ—¥å¿—
docker logs -f step-audio-r1-web   # Web UI æ—¥å¿—
```

## ğŸ“¦ Docker Hub

æ„å»ºå¹¶æ¨é€é•œåƒï¼š
```bash
docker build -t neosun/step-audio-r1:latest .
docker push neosun/step-audio-r1:latest
```

## ğŸ“ License

Apache 2.0
